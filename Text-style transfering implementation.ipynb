{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(EncoderNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.cuda(device)\n",
    "        \n",
    "    def forward(self, input_seq, hidden):\n",
    "        output, hidden = self.gru(input_seq, hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.randn(1, batch_size, self.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, h0_size, h1_size, out_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        \n",
    "        self.fcl1 = nn.Linear(input_size, h0_size)\n",
    "        self.fcl2 = nn.Linear(h0_size, h1_size)\n",
    "        self.out = nn.Linear(h1_size, out_size)\n",
    "        self.lsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fcl1(x))\n",
    "        x = F.sigmoid(self.fcl2(x))\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        \n",
    "        y = self.lsoftmax(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, device=device):\n",
    "        super(DecoderNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.lsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.cuda(device)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        output = output.view(-1, self.hidden_size)\n",
    "        output = self.lsoftmax(self.out(output))\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.randn(1, batch_size, self.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = '$SOS$'\n",
    "EOS_TOKEN = '$EOS$'\n",
    "special_tokens = (\n",
    "    SOS_TOKEN,\n",
    "    EOS_TOKEN,\n",
    ")\n",
    "\n",
    "def seq_one_hot_encode(sentence, dim_size):\n",
    "    N = sentence.size(0)\n",
    "    e_seq = torch.zeros(N, dim_size, dtype=torch.int8, device=device)\n",
    "    e_seq[torch.arange(N, dtype=torch.int64), sentence] = 1\n",
    "    \n",
    "    return e_seq\n",
    "\n",
    "def to_float(sentence, dim_size):\n",
    "    sentence = sentence.type(torch.float32)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentMultiDecoder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        encoder_hidden_size,\n",
    "        mlp_h0_size,\n",
    "        mlp_h1_size,\n",
    "        special_tokens_config,\n",
    "        decoder_max_iter,\n",
    "        device\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.mlp_h0_size = mlp_h0_size\n",
    "        self.mlp_h1_size = mlp_h1_size\n",
    "        self.special_tokens_config = special_tokens_config\n",
    "        self.decoder_max_iter = decoder_max_iter\n",
    "        self.device = device\n",
    "        \n",
    "        self.encoder = EncoderNN(input_size, encoder_hidden_size, device)\n",
    "        self.mlp_true = MLPClassifier(encoder_hidden_size, mlp_h0_size, mlp_h1_size, 2)\n",
    "        self.mlp_false = MLPClassifier(encoder_hidden_size, mlp_h0_size, mlp_h1_size, 2)\n",
    "        self.positive_decoder = DecoderNN(input_size, encoder_hidden_size, input_size, device)\n",
    "        self.negative_decoder = DecoderNN(input_size, encoder_hidden_size, input_size, device)\n",
    "        \n",
    "        self.optimizers = [\n",
    "            optim.Adam(self.encoder.parameters()),\n",
    "            optim.Adam(self.mlp_true.parameters()),\n",
    "            optim.Adam(self.mlp_false.parameters()),\n",
    "            optim.Adam(self.positive_decoder.parameters()),\n",
    "            optim.Adam(self.negative_decoder.parameters()),\n",
    "        ]\n",
    "    \n",
    "    def forward(self, X, y, fit=True, teacher_forcing=False):\n",
    "        batch_size = X.size(0)\n",
    "        \n",
    "        hidden_init = self.encoder.init_hidden(batch_size)\n",
    "        e_output, e_hidden = self.encoder.forward(X, hidden_init)\n",
    "        content_batch = e_hidden.view(batch_size, -1)\n",
    "        \n",
    "        mlp_true_out = self.mlp_true.forward(content_batch)\n",
    "        mlp_false_out = self.mlp_false.forward(content_batch)\n",
    "        \n",
    "        hidden_init = e_hidden\n",
    "        output_init = self._get_decoder_init(batch_size, self.input_size)\n",
    "        positive_mask = y == 1\n",
    "        negative_mask = ~positive_mask\n",
    "        \n",
    "        X_positive = X[positive_mask]\n",
    "        y_positive = y[positive_mask]\n",
    "        hidden_init_positive = hidden_init[:, positive_mask, :]\n",
    "        output_init_positive = output_init[positive_mask]\n",
    "        \n",
    "        X_negative = X[negative_mask]\n",
    "        y_negative = y[negative_mask]\n",
    "        hidden_init_negative = hidden_init[:, negative_mask, :]\n",
    "        output_init_negative = output_init[negative_mask]\n",
    "        output_positive = []\n",
    "        output_negative = []\n",
    "        \n",
    "        if X_positive.size(0) > 0:\n",
    "            output_positive = self.decoder_forward(\n",
    "                self.positive_decoder,\n",
    "                X_positive,\n",
    "                y_positive,\n",
    "                hidden_init_positive,\n",
    "                output_init_positive,\n",
    "                fit,\n",
    "                teacher_forcing\n",
    "            )\n",
    "            \n",
    "        if X_negative.size(0) > 0:\n",
    "            output_negative = self.decoder_forward(\n",
    "                self.negative_decoder,\n",
    "                X_negative,\n",
    "                y_negative,\n",
    "                hidden_init_negative,\n",
    "                output_init_negative,\n",
    "                fit,\n",
    "                teacher_forcing\n",
    "            )\n",
    "        \n",
    "        return mlp_true_out, mlp_false_out, output_positive, output_negative\n",
    "            \n",
    "            \n",
    "    def decoder_forward(self, decoder, X, y, hidden_init, output_init, fit, teacher_forcing=False):\n",
    "        _, sos_idx = self.special_tokens_config['SOS']\n",
    "        _, eos_idx = self.special_tokens_config['EOS']\n",
    "        output = output_init\n",
    "        hidden = hidden_init\n",
    "        \n",
    "        anses = torch.tensor([sos_idx] * X.size(0))\n",
    "        \n",
    "        decoder_seq_output = []\n",
    "        if fit:\n",
    "            for i in range(X.size(1)):\n",
    "                output, hidden = decoder.forward(output, hidden)\n",
    "                \n",
    "                output = output.view(X.size(0), 1, X.size(2))\n",
    "                decoder_seq_output.append(output)\n",
    "                if teacher_forcing:\n",
    "                    output = X[:, i:i+1, :]\n",
    "        else:\n",
    "            k = 0\n",
    "            # (anses != eos_idx).any() and \n",
    "            while (k < self.decoder_max_iter):\n",
    "                output, hidden = decoder.forward(output, hidden)\n",
    "                \n",
    "                anses = output.argmax(axis=1)\n",
    "                output = output.view(X.size(0), 1, X.size(2))\n",
    "                decoder_seq_output.append(output)\n",
    "                if teacher_forcing:\n",
    "                    output = X[:, i:i+1, :]\n",
    "                k += 1\n",
    "                \n",
    "        decoder_output = torch.cat(decoder_seq_output, dim=1)\n",
    "        return decoder_output\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.zero_grad()\n",
    "    \n",
    "    def opt_step(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.step()\n",
    "        \n",
    "    \n",
    "    def _get_decoder_init(self, batch_size, d):\n",
    "        sos_token, sos_idx = self.special_tokens_config['SOS']\n",
    "        output_init = torch.tensor([sos_idx] * batch_size, device=device)\n",
    "        output_init = seq_one_hot_encode(output_init, d)\n",
    "        output_init = output_init.view(batch_size, 1, -1)\n",
    "        output_init = to_float(output_init, d)\n",
    "        \n",
    "        return output_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        negative_examples_path,\n",
    "        positive_examples_path,\n",
    "        tokenizer,\n",
    "        normalizer,\n",
    "        device,\n",
    "        transforms=None,\n",
    "    ):\n",
    "        super(SentimentDataset, self).__init__()\n",
    "        \n",
    "        # data reading from file\n",
    "        negative_data = []\n",
    "        with open(negative_examples_path) as input_stream:\n",
    "            negative_data = input_stream.readlines()\n",
    "\n",
    "        positive_data = []\n",
    "        with open(positive_examples_path) as input_stream:\n",
    "            positive_data = input_stream.readlines()\n",
    "        # ------------------------------------\n",
    "            \n",
    "        # data processing. Norm + tokenization\n",
    "        negative_data = [tokenizer.tokenize(text) for text in negative_data]\n",
    "        negative_data = [[stemmer.stem(word) for word in text] for text in negative_data]\n",
    "\n",
    "        positive_data = [tokenizer.tokenize(text) for text in positive_data]\n",
    "        positive_data = [[stemmer.stem(word) for word in text] for text in positive_data]\n",
    "        # ------------------------------------\n",
    "        \n",
    "        # dictionary processing\n",
    "        negative_dictionary = self._get_dictionary(negative_data)\n",
    "        positive_dictionary = self._get_dictionary(positive_data)\n",
    "\n",
    "        self.dictionary = negative_dictionary.union(positive_dictionary)\n",
    "        d = len(self.dictionary)\n",
    "        \n",
    "        for token in special_tokens:\n",
    "            self.dictionary.add(token)\n",
    "        assert d + len(special_tokens) == len(self.dictionary)\n",
    "        self.dict_size = len(self.dictionary)\n",
    "        \n",
    "        self.word2idx = dict(zip(\n",
    "            self.dictionary,\n",
    "            range(self.dict_size)\n",
    "        ))\n",
    "\n",
    "        self.idx2word = {value: key for key, value in self.word2idx.items()}\n",
    "        # ------------------------------------\n",
    "        \n",
    "        # target processing\n",
    "        self.styles = np.array([0] * len(negative_data) + [1] * len(positive_data))\n",
    "\n",
    "        data = negative_data + positive_data\n",
    "        assert len(data) == len(self.styles)\n",
    "        # ------------------------------------\n",
    "        \n",
    "        self._align_corpus(data, EOS_TOKEN, self._get_corpus_max_sent_len(data) + 1)\n",
    "        data = self._map_corpus(data, self.word2idx)\n",
    "        self.data = torch.tensor(data, dtype=torch.int64, device=device)\n",
    "        self.styles = torch.tensor(self.styles, dtype=torch.int8, device=device)\n",
    "        if transforms is None:\n",
    "            transforms = []\n",
    "        self.transforms = transforms\n",
    "        self.device = device\n",
    "        \n",
    "    def _get_dictionary(self, corpus):\n",
    "        dictionary = set()\n",
    "        for text in corpus:\n",
    "            dictionary = dictionary.union(set(np.unique(text)))\n",
    "\n",
    "        return dictionary\n",
    "    \n",
    "    def _get_corpus_max_sent_len(self, corpus):\n",
    "        text_max_length = 0\n",
    "        for text in corpus:\n",
    "            if len(text) > text_max_length:\n",
    "                text_max_length = len(text)\n",
    "                \n",
    "        return text_max_length\n",
    "    \n",
    "    def _align_corpus(self, corpus, align_token, max_length):\n",
    "        for i in range(len(corpus)):\n",
    "            corpus[i] += [align_token] * max(0, (max_length - len(corpus[i])))\n",
    "\n",
    "    def _map_corpus(self, corpus, mapper):\n",
    "        return [\n",
    "            [mapper[word] for word in text]\n",
    "            for text in corpus\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        t_data = self.data[index]\n",
    "        for transform in self.transforms:\n",
    "            t_data = transform(t_data, self.dict_size)\n",
    "            \n",
    "        return t_data, self.styles[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "\n",
    "negative_examples_filename = 'sentiment_negative.raw'\n",
    "positive_examples_filename = 'sentiment_positive.raw'\n",
    "\n",
    "negative_examples_path = os.path.join(data_path, negative_examples_filename)\n",
    "positive_examples_path = os.path.join(data_path, positive_examples_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_transforms = [\n",
    "    seq_one_hot_encode,\n",
    "    to_float\n",
    "]\n",
    "\n",
    "dataset = SentimentDataset(\n",
    "    negative_examples_path,\n",
    "    positive_examples_path,\n",
    "    tokenizer,\n",
    "    stemmer,\n",
    "    device,\n",
    "    seq_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "d = dataset.dict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_config = {\n",
    "    'SOS': (SOS_TOKEN, dataset.word2idx[SOS_TOKEN]),\n",
    "    'EOS': (EOS_TOKEN, dataset.word2idx[EOS_TOKEN]),\n",
    "}\n",
    "\n",
    "def get_decoder_init(batch_size, d):\n",
    "    sos_token, sos_idx = special_tokens_config['SOS']\n",
    "    \n",
    "    output_init = torch.tensor([sos_idx] * batch_size, device=device)\n",
    "    output_init = seq_one_hot_encode(output_init, d)\n",
    "    output_init = output_init.view(batch_size, 1, -1)\n",
    "    output_init = to_float(output_init, d)\n",
    "        \n",
    "    return output_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_forward(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    X,\n",
    "):\n",
    "    input_size = X.size(2)\n",
    "    \n",
    "    encoder_hidden_init = encoder.init_hidden(X.size(0))\n",
    "    decoder_output_init = get_decoder_init(X.size(0), input_size)\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder.forward(X, encoder_hidden_init)\n",
    "    \n",
    "    decoder_seq_output = []\n",
    "    decoder_output = decoder_output_init\n",
    "    decoder_hidden = encoder_hidden\n",
    "    for i in range(X.size(1)):\n",
    "        decoder_output, decoder_hidden = decoder.forward(decoder_output, decoder_hidden)\n",
    "        \n",
    "        decoder_output = decoder_output.view(X.size(0), 1, input_size)\n",
    "        decoder_seq_output.append(decoder_output)\n",
    "        decoder_output = X[:, i:i+1, :]\n",
    "    \n",
    "    decoder_output = torch.cat(decoder_seq_output, dim=1)\n",
    "    \n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_train(\n",
    "    encoder,\n",
    "    encoder_opt,\n",
    "    decoder,\n",
    "    decoder_opt,\n",
    "    loader,\n",
    "    criterion\n",
    "):\n",
    "    for iter_num, (X, y) in enumerate(loader):\n",
    "        loss = 0\n",
    "        encoder_opt.zero_grad()\n",
    "        decoder_opt.zero_grad()\n",
    "        \n",
    "        decoder_output = autoencoder_forward(encoder, decoder, X)\n",
    "        idx_X = X.argmax(dim=2)\n",
    "        for i in range(X.size(0)):\n",
    "            loss += criterion(decoder_output[i], idx_X[i])\n",
    "            \n",
    "        loss.backward()\n",
    "        encoder_opt.step()\n",
    "        decoder_opt.step()\n",
    "        \n",
    "        if iter_num % 20 == 0:\n",
    "            print(iter_num, 'Loss: ', loss.item() / X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = d\n",
    "encoder_hidden_size = 16\n",
    "output_size = input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderNN(\n",
    "    input_size,\n",
    "    encoder_hidden_size,\n",
    "    device\n",
    ")\n",
    "\n",
    "decoder = DecoderNN(\n",
    "    input_size,\n",
    "    encoder_hidden_size,\n",
    "    output_size,\n",
    "    device\n",
    ")\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.01)\n",
    "\n",
    "nllloss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss:  8.699359893798828\n",
      "20 Loss:  4.352877140045166\n",
      "40 Loss:  3.438206195831299\n",
      "60 Loss:  2.701504707336426\n",
      "80 Loss:  2.4488210678100586\n",
      "100 Loss:  2.742182493209839\n",
      "120 Loss:  2.2706680297851562\n",
      "140 Loss:  2.5827114582061768\n",
      "160 Loss:  2.466979503631592\n",
      "180 Loss:  2.3361964225769043\n",
      "200 Loss:  2.576852560043335\n",
      "220 Loss:  2.245347023010254\n",
      "240 Loss:  2.2665770053863525\n",
      "260 Loss:  2.455225944519043\n",
      "280 Loss:  2.3000247478485107\n",
      "300 Loss:  2.3237955570220947\n",
      "320 Loss:  2.243147850036621\n",
      "340 Loss:  1.9281333684921265\n",
      "360 Loss:  2.0472254753112793\n",
      "380 Loss:  1.6999162435531616\n",
      "400 Loss:  2.2242350578308105\n",
      "420 Loss:  2.0805490016937256\n",
      "440 Loss:  2.1297738552093506\n",
      "460 Loss:  2.0762240886688232\n",
      "480 Loss:  2.013298511505127\n",
      "500 Loss:  2.3340320587158203\n",
      "520 Loss:  1.8765000104904175\n",
      "540 Loss:  2.1659328937530518\n",
      "560 Loss:  2.182204246520996\n",
      "580 Loss:  2.207395076751709\n",
      "600 Loss:  2.0523924827575684\n",
      "620 Loss:  2.104949712753296\n",
      "640 Loss:  2.722355604171753\n",
      "660 Loss:  2.0577659606933594\n",
      "680 Loss:  2.2642629146575928\n",
      "700 Loss:  2.097072124481201\n",
      "720 Loss:  1.725090503692627\n",
      "740 Loss:  1.910589575767517\n",
      "760 Loss:  2.0085253715515137\n",
      "780 Loss:  2.2483224868774414\n",
      "800 Loss:  2.0458321571350098\n",
      "820 Loss:  1.952454924583435\n",
      "840 Loss:  2.1307127475738525\n",
      "860 Loss:  1.9614691734313965\n",
      "880 Loss:  2.009455680847168\n",
      "900 Loss:  2.0211551189422607\n",
      "920 Loss:  1.8628965616226196\n",
      "940 Loss:  1.8196427822113037\n",
      "960 Loss:  2.158195972442627\n",
      "980 Loss:  2.109780788421631\n",
      "1000 Loss:  1.449165940284729\n",
      "1020 Loss:  2.058966636657715\n",
      "1040 Loss:  2.171436309814453\n",
      "1060 Loss:  1.9673058986663818\n",
      "1080 Loss:  2.1699817180633545\n",
      "1100 Loss:  1.8142924308776855\n",
      "1120 Loss:  1.8419229984283447\n",
      "1140 Loss:  1.87174654006958\n",
      "1160 Loss:  1.9629194736480713\n",
      "1180 Loss:  2.3594894409179688\n",
      "1200 Loss:  1.6631678342819214\n",
      "1220 Loss:  1.8093377351760864\n",
      "1240 Loss:  1.9687198400497437\n",
      "1260 Loss:  1.8963875770568848\n",
      "1280 Loss:  1.7301111221313477\n",
      "1300 Loss:  1.7546813488006592\n",
      "1320 Loss:  1.9915664196014404\n",
      "1340 Loss:  2.034397840499878\n",
      "1360 Loss:  2.1973648071289062\n",
      "1380 Loss:  1.9758737087249756\n",
      "1400 Loss:  2.0303714275360107\n",
      "1420 Loss:  1.976394534111023\n",
      "1440 Loss:  1.9504283666610718\n",
      "1460 Loss:  2.154005527496338\n",
      "1480 Loss:  1.680012822151184\n",
      "1500 Loss:  1.5509674549102783\n",
      "1520 Loss:  1.8621792793273926\n",
      "1540 Loss:  2.0998806953430176\n",
      "1560 Loss:  2.0619029998779297\n",
      "1580 Loss:  1.8696362972259521\n",
      "1600 Loss:  1.6809114217758179\n",
      "1620 Loss:  1.7066248655319214\n",
      "1640 Loss:  1.9093676805496216\n",
      "1660 Loss:  1.7491226196289062\n",
      "1680 Loss:  1.8344316482543945\n",
      "1700 Loss:  2.1234052181243896\n",
      "1720 Loss:  1.7169684171676636\n",
      "1740 Loss:  1.840332269668579\n",
      "1760 Loss:  1.8945910930633545\n",
      "1780 Loss:  1.6043450832366943\n",
      "1800 Loss:  1.9426065683364868\n",
      "1820 Loss:  1.7560616731643677\n",
      "1840 Loss:  2.060474157333374\n",
      "1860 Loss:  1.7920374870300293\n",
      "1880 Loss:  1.9729890823364258\n",
      "1900 Loss:  1.6308741569519043\n",
      "1920 Loss:  1.7606208324432373\n",
      "1940 Loss:  1.7081072330474854\n",
      "1960 Loss:  1.7017308473587036\n",
      "1980 Loss:  1.845901370048523\n",
      "2000 Loss:  1.8811498880386353\n",
      "2020 Loss:  2.080885171890259\n",
      "2040 Loss:  1.7710033655166626\n",
      "2060 Loss:  1.9394603967666626\n",
      "2080 Loss:  2.023266077041626\n",
      "2100 Loss:  1.6440907716751099\n",
      "2120 Loss:  1.6707113981246948\n",
      "2140 Loss:  1.4875800609588623\n",
      "2160 Loss:  1.65507173538208\n",
      "2180 Loss:  1.7036242485046387\n",
      "2200 Loss:  1.7928259372711182\n",
      "2220 Loss:  1.821060299873352\n",
      "2240 Loss:  1.6836462020874023\n",
      "2260 Loss:  1.7205816507339478\n",
      "2280 Loss:  1.7754180431365967\n",
      "2300 Loss:  1.3741568326950073\n",
      "2320 Loss:  1.6542375087738037\n",
      "2340 Loss:  1.6972355842590332\n",
      "2360 Loss:  1.6170536279678345\n",
      "2380 Loss:  1.6541838645935059\n",
      "2400 Loss:  1.8853949308395386\n",
      "2420 Loss:  1.8940387964248657\n",
      "2440 Loss:  1.6710259914398193\n",
      "2460 Loss:  2.052504777908325\n",
      "2480 Loss:  1.7486697435379028\n",
      "2500 Loss:  1.6271477937698364\n",
      "2520 Loss:  1.7971129417419434\n",
      "2540 Loss:  1.9271048307418823\n",
      "2560 Loss:  1.8119124174118042\n",
      "2580 Loss:  1.7427088022232056\n",
      "2600 Loss:  1.7612278461456299\n",
      "2620 Loss:  1.3763220310211182\n",
      "2640 Loss:  1.6027415990829468\n",
      "2660 Loss:  1.7909061908721924\n",
      "2680 Loss:  1.6572765111923218\n",
      "2700 Loss:  1.7142605781555176\n",
      "2720 Loss:  1.45868980884552\n",
      "2740 Loss:  1.5988523960113525\n",
      "2760 Loss:  1.2247735261917114\n",
      "2780 Loss:  1.5966689586639404\n",
      "2800 Loss:  1.5304011106491089\n",
      "2820 Loss:  1.6732213497161865\n",
      "2840 Loss:  1.8841713666915894\n",
      "2860 Loss:  1.6934930086135864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-27358f72c42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnllloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-2297ee77535e>\u001b[0m in \u001b[0;36mautoencoder_train\u001b[0;34m(encoder, encoder_opt, decoder, decoder_opt, loader, criterion)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdecoder_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0midx_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-8d78ce977684>\u001b[0m in \u001b[0;36mautoencoder_forward\u001b[0;34m(encoder, decoder, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-dd63d2730160>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder_train(encoder, encoder_optimizer, decoder, decoder_optimizer, loader, nllloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = autoencoder_forward(encoder, decoder, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_idx = 10\n",
    "sent = decoder_output[test_sent_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'wa', 'rude', 'and', 'useless', '.', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$']\n"
     ]
    }
   ],
   "source": [
    "print([dataset.idx2word[int(t)] for t in X.argmax(dim=2)[test_sent_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'wa', 'veri', 'and', 'the', '.', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$', '$EOS$']\n"
     ]
    }
   ],
   "source": [
    "print([dataset.idx2word[int(t)] for t in sent.argmax(dim=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.idx2word[777]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = dataset.dict_size\n",
    "encoder_hidden_size = 64\n",
    "mlp_h0_size = 64\n",
    "mlp_h1_size = 32\n",
    "special_tokens_config = {\n",
    "    'SOS': (SOS_TOKEN, dataset.word2idx[SOS_TOKEN]),\n",
    "    'EOS': (EOS_TOKEN, dataset.word2idx[EOS_TOKEN]),\n",
    "}\n",
    "decoder_max_iter = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multidecoder = SentimentMultiDecoder(\n",
    "    dict_size,\n",
    "    encoder_hidden_size,\n",
    "    mlp_h0_size,\n",
    "    mlp_h1_size,\n",
    "    special_tokens_config,\n",
    "    decoder_max_iter,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    multidecoder,\n",
    "    dataloader,\n",
    "    dataset,\n",
    "    max_iter=10000\n",
    "):\n",
    "    nll = nn.NLLLoss()\n",
    "    kld = nn.KLDivLoss()\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        if i >= max_iter:\n",
    "            break\n",
    "            \n",
    "        loss = 0\n",
    "        y = y.type(torch.int64)\n",
    "        multidecoder.zero_grad()\n",
    "        \n",
    "        positive_mask = y == 1\n",
    "        negative_mask = ~positive_mask\n",
    "        X_pos = X[positive_mask]\n",
    "        X_neg = X[negative_mask]\n",
    "        \n",
    "        y_pos = y[positive_mask]\n",
    "        y_neg = y[negative_mask]\n",
    "        \n",
    "        mlp_true_out, mlp_false_out, pos_output, neg_output = multidecoder.forward(X, y, True)\n",
    "        loss += nll(mlp_true_out, y)\n",
    "        oh_y = seq_one_hot_encode(y, 2)\n",
    "        oh_y = oh_y.type(torch.float32)\n",
    "        loss += kld(mlp_false_out, oh_y)\n",
    "        if X_pos.size(0) > 0:\n",
    "            X_pos = X_pos.argmax(axis=2)\n",
    "            for target_sent, predicted_sent in zip(X_pos, pos_output):   \n",
    "                loss += nll(predicted_sent, target_sent)\n",
    "                    \n",
    "        if X_neg.size(0) > 0:\n",
    "            X_neg = X_neg.argmax(axis=2)\n",
    "            for target_sent, predicted_sent in zip(X_neg, neg_output):\n",
    "                loss += nll(predicted_sent, target_sent)\n",
    "                    \n",
    "        loss.backward()\n",
    "        multidecoder.opt_step()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(multidecoder, loader, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_t_out, mlp_f_out, pos_output, neg_output = multidecoder.forward(x, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[t.argmax() for t in neg_output[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.idx2word[5044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.idx2word[5429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
